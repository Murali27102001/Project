{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0023854",
   "metadata": {},
   "source": [
    "# FOR BODY DAMAGE\n",
    "IMAGE PRE PROCESSING\n",
    "1. Import The ImageDataGenerator Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e869269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50714af",
   "metadata": {},
   "source": [
    "# 2. Configure ImageDataGenerator Class\n",
    "Image Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7148d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.1,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31ab30",
   "metadata": {},
   "source": [
    "# 3. Apply ImageDataGenerator Functionality To Trainset And Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49eb7d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 979 images belonging to 3 classes.\n",
      "Found 171 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/MURALI/Downloads/Dataset/Car damage/body/training',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 10,\n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/MURALI/Downloads/Dataset/Car damage/body/validation',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 10,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7b11a",
   "metadata": {},
   "source": [
    "# MODEL BUILDING\n",
    "1. Importing The Model Building Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5817a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b358b",
   "metadata": {},
   "source": [
    "# 2. Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72529de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'C:/Users/MURALI/Downloads/Dataset/Car damage/body/training'\n",
    "valid_path = 'C:/Users/MURALI/Downloads/Dataset/Car damage/body/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bdbdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9bf46",
   "metadata": {},
   "source": [
    "# 3. Adding Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009783f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4906adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('C:/Users/MURALI/Downloads/Dataset/Car damage/body/training/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d7a913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/MURALI/Downloads/Dataset/Car damage/body/training\\\\00-front',\n",
       " 'C:/Users/MURALI/Downloads/Dataset/Car damage/body/training\\\\01-rear',\n",
       " 'C:/Users/MURALI/Downloads/Dataset/Car damage/body/training\\\\02-side']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80aa7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg16.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bd1815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c9284",
   "metadata": {},
   "source": [
    "# 4. Adding Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4adad683",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00965623",
   "metadata": {},
   "source": [
    "# 5. Creating A Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "900def9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vgg16.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16f3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 75267     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,789,955\n",
      "Trainable params: 75,267\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ac5db",
   "metadata": {},
   "source": [
    "# 6. Configure The Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b57814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce35a2f",
   "metadata": {},
   "source": [
    "# 7. Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "274351f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MURALI\\AppData\\Local\\Temp\\ipykernel_16968\\563002667.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "98/98 [==============================] - 395s 4s/step - loss: 1.0367 - accuracy: 0.5618 - val_loss: 1.2905 - val_accuracy: 0.6199\n",
      "Epoch 2/25\n",
      "98/98 [==============================] - 433s 4s/step - loss: 0.7470 - accuracy: 0.6956 - val_loss: 0.9275 - val_accuracy: 0.6725\n",
      "Epoch 3/25\n",
      "98/98 [==============================] - 445s 5s/step - loss: 0.4118 - accuracy: 0.8458 - val_loss: 1.0698 - val_accuracy: 0.6199\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 433s 4s/step - loss: 0.3605 - accuracy: 0.8825 - val_loss: 1.1880 - val_accuracy: 0.5906\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 434s 4s/step - loss: 0.2914 - accuracy: 0.8774 - val_loss: 0.9338 - val_accuracy: 0.6784\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 430s 4s/step - loss: 0.2178 - accuracy: 0.9265 - val_loss: 1.0047 - val_accuracy: 0.6667\n",
      "Epoch 7/25\n",
      "98/98 [==============================] - 440s 4s/step - loss: 0.1304 - accuracy: 0.9673 - val_loss: 1.0037 - val_accuracy: 0.6784\n",
      "Epoch 8/25\n",
      "98/98 [==============================] - 395s 4s/step - loss: 0.1466 - accuracy: 0.9591 - val_loss: 1.0654 - val_accuracy: 0.6550\n",
      "Epoch 9/25\n",
      "98/98 [==============================] - 393s 4s/step - loss: 0.0978 - accuracy: 0.9724 - val_loss: 1.3960 - val_accuracy: 0.6199\n",
      "Epoch 10/25\n",
      "98/98 [==============================] - 376s 4s/step - loss: 0.1660 - accuracy: 0.9428 - val_loss: 1.0498 - val_accuracy: 0.7076\n",
      "Epoch 11/25\n",
      "98/98 [==============================] - 379s 4s/step - loss: 0.1286 - accuracy: 0.9571 - val_loss: 1.0267 - val_accuracy: 0.7193\n",
      "Epoch 12/25\n",
      "98/98 [==============================] - 377s 4s/step - loss: 0.1018 - accuracy: 0.9694 - val_loss: 1.1757 - val_accuracy: 0.6842\n",
      "Epoch 13/25\n",
      "98/98 [==============================] - 422s 4s/step - loss: 0.0774 - accuracy: 0.9816 - val_loss: 1.1078 - val_accuracy: 0.6901\n",
      "Epoch 14/25\n",
      "98/98 [==============================] - 390s 4s/step - loss: 0.0458 - accuracy: 0.9888 - val_loss: 1.2462 - val_accuracy: 0.6608\n",
      "Epoch 15/25\n",
      "98/98 [==============================] - 424s 4s/step - loss: 0.0775 - accuracy: 0.9765 - val_loss: 1.4723 - val_accuracy: 0.6433\n",
      "Epoch 16/25\n",
      "98/98 [==============================] - 401s 4s/step - loss: 0.0753 - accuracy: 0.9796 - val_loss: 1.2555 - val_accuracy: 0.6491\n",
      "Epoch 17/25\n",
      "98/98 [==============================] - 397s 4s/step - loss: 0.0753 - accuracy: 0.9837 - val_loss: 1.3016 - val_accuracy: 0.6433\n",
      "Epoch 18/25\n",
      "98/98 [==============================] - 418s 4s/step - loss: 0.1111 - accuracy: 0.9745 - val_loss: 1.8169 - val_accuracy: 0.6316\n",
      "Epoch 19/25\n",
      "98/98 [==============================] - 412s 4s/step - loss: 0.1155 - accuracy: 0.9632 - val_loss: 1.5868 - val_accuracy: 0.6374\n",
      "Epoch 20/25\n",
      "98/98 [==============================] - 432s 4s/step - loss: 0.1955 - accuracy: 0.9295 - val_loss: 1.4518 - val_accuracy: 0.6842\n",
      "Epoch 21/25\n",
      "98/98 [==============================] - 399s 4s/step - loss: 0.0828 - accuracy: 0.9734 - val_loss: 1.4527 - val_accuracy: 0.6842\n",
      "Epoch 22/25\n",
      "98/98 [==============================] - 399s 4s/step - loss: 0.0739 - accuracy: 0.9837 - val_loss: 1.5978 - val_accuracy: 0.6491\n",
      "Epoch 23/25\n",
      "98/98 [==============================] - 401s 4s/step - loss: 0.0862 - accuracy: 0.9714 - val_loss: 1.5021 - val_accuracy: 0.6725\n",
      "Epoch 24/25\n",
      "98/98 [==============================] - 397s 4s/step - loss: 0.0562 - accuracy: 0.9898 - val_loss: 1.3999 - val_accuracy: 0.7193\n",
      "Epoch 25/25\n",
      "98/98 [==============================] - 403s 4s/step - loss: 0.0459 - accuracy: 0.9898 - val_loss: 1.4858 - val_accuracy: 0.6959\n"
     ]
    }
   ],
   "source": [
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=25,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d4e7b",
   "metadata": {},
   "source": [
    "# 8. Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9277c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/MURALI/Downloads/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/body\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/MURALI/Downloads/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/body\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('C:/Users/MURALI/Downloads/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/body')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd449fd4",
   "metadata": {},
   "source": [
    "# 9. Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32276860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9af03f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('C:/Users/MURALI/Downloads/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41ffec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "  img = cv2.resize(frame,(224,224))\n",
    "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  if(np.max(img)>1):\n",
    "    img = img/255.0\n",
    "  img = np.array([img])\n",
    "  prediction = model.predict(img)\n",
    "  label = [\"front\",\"rear\",\"side\"]\n",
    "  preds = label[np.argmax(prediction)]\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21b89588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e69944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "front\n"
     ]
    }
   ],
   "source": [
    "data = \"C:/Users/MURALI/Downloads/Dataset/Car damage/body/training/00-front/0003.JPEG \"\n",
    "image = cv2.imread(data)\n",
    "print(detect(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3614e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
